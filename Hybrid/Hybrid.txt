
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 30, 30, 32)   896         input_2[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_2[0][0]                   
__________________________________________________________________________________________________
fractional_pooling2d (Fractiona (None, 9, 9, 64)     0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 9, 9, 64)     36928       fractional_pooling2d[0][0]       
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 9, 9, 64)     256         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 9, 9, 64)     36928       batch_normalization[0][0]        
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 9, 9, 64)     256         conv2d_5[0][0]                   
__________________________________________________________________________________________________
add (Add)                       (None, 9, 9, 64)     0           batch_normalization_1[0][0]      
                                                                 fractional_pooling2d[0][0]       
__________________________________________________________________________________________________
activation (Activation)         (None, 9, 9, 64)     0           add[0][0]                        
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 9, 9, 64)     36928       activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 9, 9, 64)     256         conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 9, 9, 64)     36928       batch_normalization_2[0][0]      
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 9, 9, 64)     256         conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 9, 9, 64)     0           batch_normalization_3[0][0]      
                                                                 activation[0][0]                 
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 9, 9, 64)     0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 9, 9, 64)     36928       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 9, 9, 64)     256         conv2d_8[0][0]                   
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 9, 9, 64)     36928       batch_normalization_4[0][0]      
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 9, 9, 64)     256         conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 9, 9, 64)     0           batch_normalization_5[0][0]      
                                                                 activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 9, 9, 64)     0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 9, 9, 64)     36928       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 9, 9, 64)     256         conv2d_10[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_6[0][0]      
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 9, 9, 64)     256         conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_3 (Add)                     (None, 9, 9, 64)     0           batch_normalization_7[0][0]      
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 9, 9, 64)     0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 9, 9, 64)     36928       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 9, 9, 64)     256         conv2d_12[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_8[0][0]      
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 9, 9, 64)     256         conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_4 (Add)                     (None, 9, 9, 64)     0           batch_normalization_9[0][0]      
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 9, 9, 64)     0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 9, 9, 64)     36928       activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 9, 9, 64)     256         conv2d_14[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_10[0][0]     
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 9, 9, 64)     256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 9, 9, 64)     0           batch_normalization_11[0][0]     
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 9, 9, 64)     0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 9, 9, 64)     36928       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 9, 9, 64)     256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_12[0][0]     
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 9, 9, 64)     256         conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 9, 9, 64)     0           batch_normalization_13[0][0]     
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 9, 9, 64)     0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 9, 9, 64)     36928       activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 9, 9, 64)     256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_14[0][0]     
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 9, 9, 64)     256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 9, 9, 64)     0           batch_normalization_15[0][0]     
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 9, 9, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 9, 9, 64)     36928       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 9, 9, 64)     256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_16[0][0]     
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 9, 9, 64)     256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 9, 9, 64)     0           batch_normalization_17[0][0]     
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 9, 9, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 9, 9, 64)     36928       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 9, 9, 64)     256         conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 9, 9, 64)     36928       batch_normalization_18[0][0]     
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 9, 9, 64)     256         conv2d_23[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 9, 9, 64)     0           batch_normalization_19[0][0]     
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 9, 9, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 7, 7, 64)     36928       activation_9[0][0]               
__________________________________________________________________________________________________
fractional_pooling2d_1 (Fractio (None, 2, 2, 64)     0           conv2d_24[0][0]                  
__________________________________________________________________________________________________
flatten (Flatten)               (None, 256)          0           fractional_pooling2d_1[0][0]     
__________________________________________________________________________________________________
dense (Dense)                   (None, 256)          65792       flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           2570        dense[0][0]                      
==================================================================================================
Total params: 868,362
Trainable params: 865,802
Non-trainable params: 2,560
__________________________________________________________________________________________________
None


Test Details

Train for 100 steps, validate for 3 steps
Epoch 1/50
 99/100 [============================>.] - ETA: 0s - loss: 2.1815 - acc: 0.2424
Epoch 00001: val_loss improved from inf to 2.11514, saving model to Model.hdf5
100/100 [==============================] - 26s 258ms/step - loss: 2.1769 - acc: 0.2436 - val_loss: 2.1151 - val_acc: 0.1822
Epoch 2/50
 99/100 [============================>.] - ETA: 0s - loss: 1.7439 - acc: 0.3551
Epoch 00002: val_loss did not improve from 2.11514
100/100 [==============================] - 14s 136ms/step - loss: 1.7435 - acc: 0.3548 - val_loss: 2.3137 - val_acc: 0.1614
Epoch 3/50
 99/100 [============================>.] - ETA: 0s - loss: 1.6068 - acc: 0.4107
Epoch 00003: val_loss improved from 2.11514 to 2.11435, saving model to Model.hdf5
100/100 [==============================] - 13s 134ms/step - loss: 1.6072 - acc: 0.4106 - val_loss: 2.1144 - val_acc: 0.2448
Epoch 4/50
 99/100 [============================>.] - ETA: 0s - loss: 1.4843 - acc: 0.4574
Epoch 00004: val_loss did not improve from 2.11435
100/100 [==============================] - 13s 131ms/step - loss: 1.4850 - acc: 0.4578 - val_loss: 2.4731 - val_acc: 0.2173
Epoch 5/50
 99/100 [============================>.] - ETA: 0s - loss: 1.4401 - acc: 0.4787
Epoch 00005: val_loss improved from 2.11435 to 1.48022, saving model to Model.hdf5
100/100 [==============================] - 13s 134ms/step - loss: 1.4403 - acc: 0.4781 - val_loss: 1.4802 - val_acc: 0.4569
Epoch 6/50
 99/100 [============================>.] - ETA: 0s - loss: 1.3698 - acc: 0.5077
Epoch 00006: val_loss improved from 1.48022 to 1.47683, saving model to Model.hdf5
100/100 [==============================] - 14s 137ms/step - loss: 1.3740 - acc: 0.5066 - val_loss: 1.4768 - val_acc: 0.4751
Epoch 7/50
 99/100 [============================>.] - ETA: 0s - loss: 1.3197 - acc: 0.5305
Epoch 00007: val_loss did not improve from 1.47683
100/100 [==============================] - 13s 130ms/step - loss: 1.3202 - acc: 0.5304 - val_loss: 1.5711 - val_acc: 0.4459
Epoch 8/50
 99/100 [============================>.] - ETA: 0s - loss: 1.2585 - acc: 0.5600
Epoch 00008: val_loss improved from 1.47683 to 1.37146, saving model to Model.hdf5
100/100 [==============================] - 14s 137ms/step - loss: 1.2591 - acc: 0.5592 - val_loss: 1.3715 - val_acc: 0.5105
Epoch 9/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1615 - acc: 0.5873
Epoch 00009: val_loss did not improve from 1.37146
100/100 [==============================] - 13s 130ms/step - loss: 1.1611 - acc: 0.5875 - val_loss: 1.4161 - val_acc: 0.5089
Epoch 10/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1767 - acc: 0.5790
Epoch 00010: val_loss did not improve from 1.37146
100/100 [==============================] - 13s 126ms/step - loss: 1.1749 - acc: 0.5806 - val_loss: 1.3797 - val_acc: 0.5294
Epoch 11/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1166 - acc: 0.6020
Epoch 00011: val_loss improved from 1.37146 to 1.32984, saving model to Model.hdf5
100/100 [==============================] - 14s 135ms/step - loss: 1.1165 - acc: 0.6017 - val_loss: 1.3298 - val_acc: 0.5297
Epoch 12/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0689 - acc: 0.6174
Epoch 00012: val_loss improved from 1.32984 to 1.23055, saving model to Model.hdf5
100/100 [==============================] - 13s 130ms/step - loss: 1.0694 - acc: 0.6170 - val_loss: 1.2306 - val_acc: 0.5723
Epoch 13/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0320 - acc: 0.6384
Epoch 00013: val_loss did not improve from 1.23055
100/100 [==============================] - 13s 131ms/step - loss: 1.0342 - acc: 0.6381 - val_loss: 2.9603 - val_acc: 0.3075
Epoch 14/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0487 - acc: 0.6233
Epoch 00014: val_loss did not improve from 1.23055
100/100 [==============================] - 12s 124ms/step - loss: 1.0491 - acc: 0.6231 - val_loss: 1.2711 - val_acc: 0.5663
Epoch 15/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0103 - acc: 0.6496
Epoch 00015: val_loss did not improve from 1.23055
100/100 [==============================] - 14s 135ms/step - loss: 1.0117 - acc: 0.6488 - val_loss: 1.3489 - val_acc: 0.5415
Epoch 16/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9730 - acc: 0.6564
Epoch 00016: val_loss improved from 1.23055 to 1.06176, saving model to Model.hdf5
100/100 [==============================] - 13s 131ms/step - loss: 0.9745 - acc: 0.6558 - val_loss: 1.0618 - val_acc: 0.6331
Epoch 17/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9043 - acc: 0.6807
Epoch 00017: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 130ms/step - loss: 0.9066 - acc: 0.6795 - val_loss: 1.3958 - val_acc: 0.5383
Epoch 18/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9332 - acc: 0.6706
Epoch 00018: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 126ms/step - loss: 0.9318 - acc: 0.6708 - val_loss: 1.1448 - val_acc: 0.5993
Epoch 19/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9046 - acc: 0.6806
Epoch 00019: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 125ms/step - loss: 0.9034 - acc: 0.6814 - val_loss: 1.0808 - val_acc: 0.6273
Epoch 20/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8899 - acc: 0.6850
Epoch 00020: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 128ms/step - loss: 0.8904 - acc: 0.6845 - val_loss: 1.2597 - val_acc: 0.5825
Epoch 21/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8898 - acc: 0.6881
Epoch 00021: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 128ms/step - loss: 0.8892 - acc: 0.6886 - val_loss: 1.3706 - val_acc: 0.5696
Epoch 22/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8515 - acc: 0.6964
Epoch 00022: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 132ms/step - loss: 0.8508 - acc: 0.6971 - val_loss: 1.0814 - val_acc: 0.6341
Epoch 23/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8680 - acc: 0.7000
Epoch 00023: val_loss did not improve from 1.06176
100/100 [==============================] - 13s 127ms/step - loss: 0.8658 - acc: 0.7009 - val_loss: 1.0680 - val_acc: 0.6326
Epoch 24/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8150 - acc: 0.7176
Epoch 00024: val_loss improved from 1.06176 to 1.00362, saving model to Model.hdf5
100/100 [==============================] - 13s 135ms/step - loss: 0.8140 - acc: 0.7177 - val_loss: 1.0036 - val_acc: 0.6527
Epoch 25/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7863 - acc: 0.7246
Epoch 00025: val_loss improved from 1.00362 to 0.95563, saving model to Model.hdf5
100/100 [==============================] - 13s 134ms/step - loss: 0.7867 - acc: 0.7250 - val_loss: 0.9556 - val_acc: 0.6651
Epoch 26/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7979 - acc: 0.7153
Epoch 00026: val_loss did not improve from 0.95563
100/100 [==============================] - 13s 131ms/step - loss: 0.7977 - acc: 0.7155 - val_loss: 0.9584 - val_acc: 0.6697
Epoch 27/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7921 - acc: 0.7200
Epoch 00027: val_loss did not improve from 0.95563
100/100 [==============================] - 13s 127ms/step - loss: 0.7922 - acc: 0.7206 - val_loss: 1.0455 - val_acc: 0.6445
Epoch 28/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7752 - acc: 0.7251
Epoch 00028: val_loss did not improve from 0.95563
100/100 [==============================] - 13s 126ms/step - loss: 0.7735 - acc: 0.7259 - val_loss: 1.0695 - val_acc: 0.6372
Epoch 29/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8017 - acc: 0.7128
Epoch 00029: val_loss improved from 0.95563 to 0.84026, saving model to Model.hdf5
100/100 [==============================] - 14s 136ms/step - loss: 0.8008 - acc: 0.7125 - val_loss: 0.8403 - val_acc: 0.7129
Epoch 30/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7486 - acc: 0.7399
Epoch 00030: val_loss did not improve from 0.84026
100/100 [==============================] - 13s 127ms/step - loss: 0.7490 - acc: 0.7394 - val_loss: 1.1210 - val_acc: 0.6421
Epoch 31/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7521 - acc: 0.7396
Epoch 00031: val_loss did not improve from 0.84026
100/100 [==============================] - 13s 125ms/step - loss: 0.7543 - acc: 0.7394 - val_loss: 1.1249 - val_acc: 0.6404
Epoch 32/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7123 - acc: 0.7472
Epoch 00032: val_loss did not improve from 0.84026
100/100 [==============================] - 13s 130ms/step - loss: 0.7107 - acc: 0.7475 - val_loss: 1.1855 - val_acc: 0.6133
Epoch 33/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6979 - acc: 0.7541
Epoch 00033: val_loss did not improve from 0.84026
100/100 [==============================] - 13s 128ms/step - loss: 0.6981 - acc: 0.7545 - val_loss: 0.9310 - val_acc: 0.6856
Epoch 34/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7239 - acc: 0.7517
Epoch 00034: val_loss did not improve from 0.84026
100/100 [==============================] - 13s 126ms/step - loss: 0.7222 - acc: 0.7520 - val_loss: 0.8931 - val_acc: 0.6902
Epoch 35/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6974 - acc: 0.7576
Epoch 00035: val_loss did not improve from 0.84026
100/100 [==============================] - 12s 124ms/step - loss: 0.6956 - acc: 0.7583 - val_loss: 1.1458 - val_acc: 0.6553
Epoch 36/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7050 - acc: 0.7590
Epoch 00036: val_loss improved from 0.84026 to 0.78606, saving model to Model.hdf5
100/100 [==============================] - 13s 130ms/step - loss: 0.7064 - acc: 0.7581 - val_loss: 0.7861 - val_acc: 0.7306
Epoch 37/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6956 - acc: 0.7620
Epoch 00037: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 130ms/step - loss: 0.6943 - acc: 0.7622 - val_loss: 0.8069 - val_acc: 0.7213
Epoch 38/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6955 - acc: 0.7530
Epoch 00038: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 130ms/step - loss: 0.6943 - acc: 0.7534 - val_loss: 0.9715 - val_acc: 0.6779
Epoch 39/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6889 - acc: 0.7590
Epoch 00039: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 127ms/step - loss: 0.6892 - acc: 0.7589 - val_loss: 0.9693 - val_acc: 0.6795
Epoch 40/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6184 - acc: 0.7849
Epoch 00040: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 128ms/step - loss: 0.6179 - acc: 0.7848 - val_loss: 1.0608 - val_acc: 0.6424
Epoch 41/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6317 - acc: 0.7825
Epoch 00041: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 133ms/step - loss: 0.6308 - acc: 0.7830 - val_loss: 1.0505 - val_acc: 0.6355
Epoch 42/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6766 - acc: 0.7658
Epoch 00042: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 128ms/step - loss: 0.6787 - acc: 0.7653 - val_loss: 0.9603 - val_acc: 0.6841
Epoch 43/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6449 - acc: 0.7734
Epoch 00043: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 127ms/step - loss: 0.6454 - acc: 0.7731 - val_loss: 1.0334 - val_acc: 0.6558
Epoch 44/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6536 - acc: 0.7672
Epoch 00044: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 129ms/step - loss: 0.6552 - acc: 0.7666 - val_loss: 0.8044 - val_acc: 0.7307
Epoch 45/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6579 - acc: 0.7727
Epoch 00045: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 128ms/step - loss: 0.6580 - acc: 0.7723 - val_loss: 0.8836 - val_acc: 0.7125
Epoch 46/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6341 - acc: 0.7790
Epoch 00046: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 127ms/step - loss: 0.6330 - acc: 0.7792 - val_loss: 0.8536 - val_acc: 0.7050
Epoch 47/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6311 - acc: 0.7812
Epoch 00047: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 130ms/step - loss: 0.6299 - acc: 0.7816 - val_loss: 0.8600 - val_acc: 0.7135
Epoch 48/50
 99/100 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.7994
Epoch 00048: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 130ms/step - loss: 0.5687 - acc: 0.7987 - val_loss: 0.9661 - val_acc: 0.6874
Epoch 49/50
 99/100 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.7931
Epoch 00049: val_loss did not improve from 0.78606
100/100 [==============================] - 12s 121ms/step - loss: 0.5876 - acc: 0.7939 - val_loss: 0.8820 - val_acc: 0.6942
Epoch 50/50
 99/100 [============================>.] - ETA: 0s - loss: 0.5648 - acc: 0.8056
Epoch 00050: val_loss did not improve from 0.78606
100/100 [==============================] - 13s 128ms/step - loss: 0.5641 - acc: 0.8058 - val_loss: 0.8115 - val_acc: 0.7285