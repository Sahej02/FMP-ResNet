Model Summary

Model: "model_3"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 30, 30, 32)   896         input_4[0][0]                    
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 28, 28, 64)   18496       conv2d_129[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_6 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_130[0][0]                 
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 9, 9, 64)     36928       max_pooling2d_6[0][0]            
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 9, 9, 64)     256         conv2d_131[0][0]                 
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_120[0][0]    
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 9, 9, 64)     256         conv2d_132[0][0]                 
__________________________________________________________________________________________________
add_60 (Add)                    (None, 9, 9, 64)     0           batch_normalization_121[0][0]    
                                                                 max_pooling2d_6[0][0]            
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 9, 9, 64)     0           add_60[0][0]                     
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 9, 9, 64)     36928       activation_60[0][0]              
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 9, 9, 64)     256         conv2d_133[0][0]                 
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_122[0][0]    
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 9, 9, 64)     256         conv2d_134[0][0]                 
__________________________________________________________________________________________________
add_61 (Add)                    (None, 9, 9, 64)     0           batch_normalization_123[0][0]    
                                                                 activation_60[0][0]              
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 9, 9, 64)     0           add_61[0][0]                     
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 9, 9, 64)     36928       activation_61[0][0]              
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 9, 9, 64)     256         conv2d_135[0][0]                 
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_124[0][0]    
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 9, 9, 64)     256         conv2d_136[0][0]                 
__________________________________________________________________________________________________
add_62 (Add)                    (None, 9, 9, 64)     0           batch_normalization_125[0][0]    
                                                                 activation_61[0][0]              
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 9, 9, 64)     0           add_62[0][0]                     
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 9, 9, 64)     36928       activation_62[0][0]              
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 9, 9, 64)     256         conv2d_137[0][0]                 
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_126[0][0]    
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 9, 9, 64)     256         conv2d_138[0][0]                 
__________________________________________________________________________________________________
add_63 (Add)                    (None, 9, 9, 64)     0           batch_normalization_127[0][0]    
                                                                 activation_62[0][0]              
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 9, 9, 64)     0           add_63[0][0]                     
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 9, 9, 64)     36928       activation_63[0][0]              
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 9, 9, 64)     256         conv2d_139[0][0]                 
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_128[0][0]    
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 9, 9, 64)     256         conv2d_140[0][0]                 
__________________________________________________________________________________________________
add_64 (Add)                    (None, 9, 9, 64)     0           batch_normalization_129[0][0]    
                                                                 activation_63[0][0]              
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 9, 9, 64)     0           add_64[0][0]                     
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 9, 9, 64)     36928       activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 9, 9, 64)     256         conv2d_141[0][0]                 
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_130[0][0]    
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 9, 9, 64)     256         conv2d_142[0][0]                 
__________________________________________________________________________________________________
add_65 (Add)                    (None, 9, 9, 64)     0           batch_normalization_131[0][0]    
                                                                 activation_64[0][0]              
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 9, 9, 64)     0           add_65[0][0]                     
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 9, 9, 64)     36928       activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 9, 9, 64)     256         conv2d_143[0][0]                 
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_132[0][0]    
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 9, 9, 64)     256         conv2d_144[0][0]                 
__________________________________________________________________________________________________
add_66 (Add)                    (None, 9, 9, 64)     0           batch_normalization_133[0][0]    
                                                                 activation_65[0][0]              
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 9, 9, 64)     0           add_66[0][0]                     
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 9, 9, 64)     36928       activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 9, 9, 64)     256         conv2d_145[0][0]                 
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_134[0][0]    
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 9, 9, 64)     256         conv2d_146[0][0]                 
__________________________________________________________________________________________________
add_67 (Add)                    (None, 9, 9, 64)     0           batch_normalization_135[0][0]    
                                                                 activation_66[0][0]              
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 9, 9, 64)     0           add_67[0][0]                     
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 9, 9, 64)     36928       activation_67[0][0]              
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 9, 9, 64)     256         conv2d_147[0][0]                 
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_136[0][0]    
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 9, 9, 64)     256         conv2d_148[0][0]                 
__________________________________________________________________________________________________
add_68 (Add)                    (None, 9, 9, 64)     0           batch_normalization_137[0][0]    
                                                                 activation_67[0][0]              
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 9, 9, 64)     0           add_68[0][0]                     
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 9, 9, 64)     36928       activation_68[0][0]              
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 9, 9, 64)     256         conv2d_149[0][0]                 
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_138[0][0]    
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 9, 9, 64)     256         conv2d_150[0][0]                 
__________________________________________________________________________________________________
add_69 (Add)                    (None, 9, 9, 64)     0           batch_normalization_139[0][0]    
                                                                 activation_68[0][0]              
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 9, 9, 64)     0           add_69[0][0]                     
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 9, 9, 64)     36928       activation_69[0][0]              
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 9, 9, 64)     256         conv2d_151[0][0]                 
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_140[0][0]    
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 9, 9, 64)     256         conv2d_152[0][0]                 
__________________________________________________________________________________________________
add_70 (Add)                    (None, 9, 9, 64)     0           batch_normalization_141[0][0]    
                                                                 activation_69[0][0]              
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 9, 9, 64)     0           add_70[0][0]                     
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 9, 9, 64)     36928       activation_70[0][0]              
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 9, 9, 64)     256         conv2d_153[0][0]                 
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_142[0][0]    
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 9, 9, 64)     256         conv2d_154[0][0]                 
__________________________________________________________________________________________________
add_71 (Add)                    (None, 9, 9, 64)     0           batch_normalization_143[0][0]    
                                                                 activation_70[0][0]              
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 9, 9, 64)     0           add_71[0][0]                     
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 9, 9, 64)     36928       activation_71[0][0]              
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 9, 9, 64)     256         conv2d_155[0][0]                 
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_144[0][0]    
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 9, 9, 64)     256         conv2d_156[0][0]                 
__________________________________________________________________________________________________
add_72 (Add)                    (None, 9, 9, 64)     0           batch_normalization_145[0][0]    
                                                                 activation_71[0][0]              
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 9, 9, 64)     0           add_72[0][0]                     
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 9, 9, 64)     36928       activation_72[0][0]              
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 9, 9, 64)     256         conv2d_157[0][0]                 
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_146[0][0]    
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 9, 9, 64)     256         conv2d_158[0][0]                 
__________________________________________________________________________________________________
add_73 (Add)                    (None, 9, 9, 64)     0           batch_normalization_147[0][0]    
                                                                 activation_72[0][0]              
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 9, 9, 64)     0           add_73[0][0]                     
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 9, 9, 64)     36928       activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 9, 9, 64)     256         conv2d_159[0][0]                 
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_148[0][0]    
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 9, 9, 64)     256         conv2d_160[0][0]                 
__________________________________________________________________________________________________
add_74 (Add)                    (None, 9, 9, 64)     0           batch_normalization_149[0][0]    
                                                                 activation_73[0][0]              
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 9, 9, 64)     0           add_74[0][0]                     
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 9, 9, 64)     36928       activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 9, 9, 64)     256         conv2d_161[0][0]                 
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_150[0][0]    
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 9, 9, 64)     256         conv2d_162[0][0]                 
__________________________________________________________________________________________________
add_75 (Add)                    (None, 9, 9, 64)     0           batch_normalization_151[0][0]    
                                                                 activation_74[0][0]              
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 9, 9, 64)     0           add_75[0][0]                     
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 9, 9, 64)     36928       activation_75[0][0]              
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 9, 9, 64)     256         conv2d_163[0][0]                 
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_152[0][0]    
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 9, 9, 64)     256         conv2d_164[0][0]                 
__________________________________________________________________________________________________
add_76 (Add)                    (None, 9, 9, 64)     0           batch_normalization_153[0][0]    
                                                                 activation_75[0][0]              
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 9, 9, 64)     0           add_76[0][0]                     
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 9, 9, 64)     36928       activation_76[0][0]              
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 9, 9, 64)     256         conv2d_165[0][0]                 
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_154[0][0]    
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 9, 9, 64)     256         conv2d_166[0][0]                 
__________________________________________________________________________________________________
add_77 (Add)                    (None, 9, 9, 64)     0           batch_normalization_155[0][0]    
                                                                 activation_76[0][0]              
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 9, 9, 64)     0           add_77[0][0]                     
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 9, 9, 64)     36928       activation_77[0][0]              
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 9, 9, 64)     256         conv2d_167[0][0]                 
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_156[0][0]    
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 9, 9, 64)     256         conv2d_168[0][0]                 
__________________________________________________________________________________________________
add_78 (Add)                    (None, 9, 9, 64)     0           batch_normalization_157[0][0]    
                                                                 activation_77[0][0]              
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 9, 9, 64)     0           add_78[0][0]                     
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 9, 9, 64)     36928       activation_78[0][0]              
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 9, 9, 64)     256         conv2d_169[0][0]                 
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 9, 9, 64)     36928       batch_normalization_158[0][0]    
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 9, 9, 64)     256         conv2d_170[0][0]                 
__________________________________________________________________________________________________
add_79 (Add)                    (None, 9, 9, 64)     0           batch_normalization_159[0][0]    
                                                                 activation_78[0][0]              
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 9, 9, 64)     0           add_79[0][0]                     
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 7, 7, 64)     36928       activation_79[0][0]              
__________________________________________________________________________________________________
max_pooling2d_7 (MaxPooling2D)  (None, 2, 2, 64)     0           conv2d_171[0][0]                 
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 256)          0           max_pooling2d_7[0][0]            
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 256)          65792       flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 10)           2570        dense_6[0][0]                    
==================================================================================================
Total params: 1,612,042
Trainable params: 1,606,922
Non-trainable params: 5,120
__________________________________________________________________________________________________
None


Training Details


Train for 100 steps, validate for 3 steps
Epoch 1/50
 99/100 [============================>.] - ETA: 0s - loss: 2.5293 - acc: 0.2196
Epoch 00001: val_loss improved from inf to 2.58267, saving model to Model.hdf5
100/100 [==============================] - 23s 230ms/step - loss: 2.5236 - acc: 0.2206 - val_loss: 2.5827 - val_acc: 0.1255
Epoch 2/50
 99/100 [============================>.] - ETA: 0s - loss: 1.8858 - acc: 0.3060
Epoch 00002: val_loss did not improve from 2.58267
100/100 [==============================] - 14s 143ms/step - loss: 1.8844 - acc: 0.3067 - val_loss: 3.1183 - val_acc: 0.1098
Epoch 3/50
 99/100 [============================>.] - ETA: 0s - loss: 1.7392 - acc: 0.3510
Epoch 00003: val_loss did not improve from 2.58267
100/100 [==============================] - 14s 144ms/step - loss: 1.7410 - acc: 0.3500 - val_loss: 3.0043 - val_acc: 0.1057
Epoch 4/50
 99/100 [============================>.] - ETA: 0s - loss: 1.6707 - acc: 0.3873
Epoch 00004: val_loss improved from 2.58267 to 2.36161, saving model to Model.hdf5
100/100 [==============================] - 15s 150ms/step - loss: 1.6713 - acc: 0.3873 - val_loss: 2.3616 - val_acc: 0.2067
Epoch 5/50
 99/100 [============================>.] - ETA: 0s - loss: 1.6182 - acc: 0.4096
Epoch 00005: val_loss improved from 2.36161 to 1.72276, saving model to Model.hdf5
100/100 [==============================] - 15s 149ms/step - loss: 1.6209 - acc: 0.4095 - val_loss: 1.7228 - val_acc: 0.3654
Epoch 6/50
 99/100 [============================>.] - ETA: 0s - loss: 1.5592 - acc: 0.4354
Epoch 00006: val_loss did not improve from 1.72276
100/100 [==============================] - 14s 143ms/step - loss: 1.5581 - acc: 0.4355 - val_loss: 1.8011 - val_acc: 0.3664
Epoch 7/50
 99/100 [============================>.] - ETA: 0s - loss: 1.5224 - acc: 0.4487
Epoch 00007: val_loss improved from 1.72276 to 1.59775, saving model to Model.hdf5
100/100 [==============================] - 15s 148ms/step - loss: 1.5228 - acc: 0.4487 - val_loss: 1.5978 - val_acc: 0.4234
Epoch 8/50
 99/100 [============================>.] - ETA: 0s - loss: 1.4444 - acc: 0.4814
Epoch 00008: val_loss improved from 1.59775 to 1.57061, saving model to Model.hdf5
100/100 [==============================] - 15s 152ms/step - loss: 1.4430 - acc: 0.4817 - val_loss: 1.5706 - val_acc: 0.4595
Epoch 9/50
 99/100 [============================>.] - ETA: 0s - loss: 1.4119 - acc: 0.4908
Epoch 00009: val_loss improved from 1.57061 to 1.52080, saving model to Model.hdf5
100/100 [==============================] - 15s 150ms/step - loss: 1.4091 - acc: 0.4917 - val_loss: 1.5208 - val_acc: 0.4535
Epoch 10/50
 99/100 [============================>.] - ETA: 0s - loss: 1.3670 - acc: 0.5127
Epoch 00010: val_loss improved from 1.52080 to 1.49146, saving model to Model.hdf5
100/100 [==============================] - 15s 148ms/step - loss: 1.3662 - acc: 0.5131 - val_loss: 1.4915 - val_acc: 0.4658
Epoch 11/50
 99/100 [============================>.] - ETA: 0s - loss: 1.3234 - acc: 0.5294
Epoch 00011: val_loss did not improve from 1.49146
100/100 [==============================] - 14s 143ms/step - loss: 1.3241 - acc: 0.5295 - val_loss: 1.6681 - val_acc: 0.3931
Epoch 12/50
 99/100 [============================>.] - ETA: 0s - loss: 1.2861 - acc: 0.5407
Epoch 00012: val_loss improved from 1.49146 to 1.36903, saving model to Model.hdf5
100/100 [==============================] - 15s 150ms/step - loss: 1.2850 - acc: 0.5412 - val_loss: 1.3690 - val_acc: 0.5182
Epoch 13/50
 99/100 [============================>.] - ETA: 0s - loss: 1.2467 - acc: 0.5530
Epoch 00013: val_loss did not improve from 1.36903
100/100 [==============================] - 14s 145ms/step - loss: 1.2431 - acc: 0.5541 - val_loss: 1.4940 - val_acc: 0.4735
Epoch 14/50
 99/100 [============================>.] - ETA: 0s - loss: 1.2332 - acc: 0.5600
Epoch 00014: val_loss improved from 1.36903 to 1.33633, saving model to Model.hdf5
100/100 [==============================] - 15s 149ms/step - loss: 1.2315 - acc: 0.5608 - val_loss: 1.3363 - val_acc: 0.5330
Epoch 15/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1720 - acc: 0.5822
Epoch 00015: val_loss did not improve from 1.33633
100/100 [==============================] - 14s 143ms/step - loss: 1.1709 - acc: 0.5827 - val_loss: 1.3594 - val_acc: 0.5266
Epoch 16/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1709 - acc: 0.5863
Epoch 00016: val_loss did not improve from 1.33633
100/100 [==============================] - 15s 146ms/step - loss: 1.1705 - acc: 0.5856 - val_loss: 1.5792 - val_acc: 0.4950
Epoch 17/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0867 - acc: 0.6102
Epoch 00017: val_loss did not improve from 1.33633
100/100 [==============================] - 14s 144ms/step - loss: 1.0869 - acc: 0.6103 - val_loss: 1.7490 - val_acc: 0.4745
Epoch 18/50
 99/100 [============================>.] - ETA: 0s - loss: 1.1103 - acc: 0.6037
Epoch 00018: val_loss did not improve from 1.33633
100/100 [==============================] - 14s 143ms/step - loss: 1.1079 - acc: 0.6044 - val_loss: 1.5863 - val_acc: 0.4915
Epoch 19/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0770 - acc: 0.6209
Epoch 00019: val_loss improved from 1.33633 to 1.14258, saving model to Model.hdf5
100/100 [==============================] - 15s 148ms/step - loss: 1.0772 - acc: 0.6209 - val_loss: 1.1426 - val_acc: 0.5949
Epoch 20/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0587 - acc: 0.6280
Epoch 00020: val_loss did not improve from 1.14258
100/100 [==============================] - 14s 142ms/step - loss: 1.0558 - acc: 0.6288 - val_loss: 1.3634 - val_acc: 0.5387
Epoch 21/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0439 - acc: 0.6381
Epoch 00021: val_loss did not improve from 1.14258
100/100 [==============================] - 14s 144ms/step - loss: 1.0440 - acc: 0.6373 - val_loss: 1.2234 - val_acc: 0.5695
Epoch 22/50
 99/100 [============================>.] - ETA: 0s - loss: 1.0169 - acc: 0.6413
Epoch 00022: val_loss did not improve from 1.14258
100/100 [==============================] - 14s 145ms/step - loss: 1.0179 - acc: 0.6405 - val_loss: 1.5847 - val_acc: 0.4942
Epoch 23/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9676 - acc: 0.6651
Epoch 00023: val_loss did not improve from 1.14258
100/100 [==============================] - 14s 143ms/step - loss: 0.9685 - acc: 0.6645 - val_loss: 1.2888 - val_acc: 0.5661
Epoch 24/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9524 - acc: 0.6682
Epoch 00024: val_loss improved from 1.14258 to 0.98950, saving model to Model.hdf5
100/100 [==============================] - 15s 151ms/step - loss: 0.9520 - acc: 0.6686 - val_loss: 0.9895 - val_acc: 0.6547
Epoch 25/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.6755
Epoch 00025: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 142ms/step - loss: 0.9224 - acc: 0.6761 - val_loss: 1.0176 - val_acc: 0.6477
Epoch 26/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9180 - acc: 0.6809
Epoch 00026: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 142ms/step - loss: 0.9173 - acc: 0.6811 - val_loss: 1.1184 - val_acc: 0.6154
Epoch 27/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8936 - acc: 0.6888
Epoch 00027: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 142ms/step - loss: 0.8927 - acc: 0.6891 - val_loss: 1.0708 - val_acc: 0.6292
Epoch 28/50
 99/100 [============================>.] - ETA: 0s - loss: 0.9044 - acc: 0.6853
Epoch 00028: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 144ms/step - loss: 0.9032 - acc: 0.6853 - val_loss: 1.1123 - val_acc: 0.6291
Epoch 29/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8913 - acc: 0.6878
Epoch 00029: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 143ms/step - loss: 0.8946 - acc: 0.6864 - val_loss: 1.5202 - val_acc: 0.5461
Epoch 30/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8652 - acc: 0.6911
Epoch 00030: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 144ms/step - loss: 0.8646 - acc: 0.6919 - val_loss: 0.9960 - val_acc: 0.6671
Epoch 31/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8612 - acc: 0.6989
Epoch 00031: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 144ms/step - loss: 0.8627 - acc: 0.6986 - val_loss: 1.3700 - val_acc: 0.5526
Epoch 32/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8369 - acc: 0.7057
Epoch 00032: val_loss did not improve from 0.98950
100/100 [==============================] - 15s 147ms/step - loss: 0.8355 - acc: 0.7063 - val_loss: 1.1748 - val_acc: 0.5984
Epoch 33/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7969 - acc: 0.7282
Epoch 00033: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 143ms/step - loss: 0.7968 - acc: 0.7278 - val_loss: 1.1203 - val_acc: 0.6325
Epoch 34/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8164 - acc: 0.7105
Epoch 00034: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 144ms/step - loss: 0.8160 - acc: 0.7109 - val_loss: 1.0704 - val_acc: 0.6437
Epoch 35/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7656 - acc: 0.7339
Epoch 00035: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 145ms/step - loss: 0.7665 - acc: 0.7331 - val_loss: 1.0832 - val_acc: 0.6203
Epoch 36/50
 99/100 [============================>.] - ETA: 0s - loss: 0.8141 - acc: 0.7153
Epoch 00036: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 144ms/step - loss: 0.8136 - acc: 0.7150 - val_loss: 1.0975 - val_acc: 0.6354
Epoch 37/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7762 - acc: 0.7301
Epoch 00037: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 145ms/step - loss: 0.7757 - acc: 0.7306 - val_loss: 1.5610 - val_acc: 0.5477
Epoch 38/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7789 - acc: 0.7233
Epoch 00038: val_loss did not improve from 0.98950
100/100 [==============================] - 14s 145ms/step - loss: 0.7782 - acc: 0.7228 - val_loss: 0.9950 - val_acc: 0.6649
Epoch 39/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7715 - acc: 0.7361
Epoch 00039: val_loss improved from 0.98950 to 0.96692, saving model to Model.hdf5
100/100 [==============================] - 15s 150ms/step - loss: 0.7707 - acc: 0.7364 - val_loss: 0.9669 - val_acc: 0.6603
Epoch 40/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.7596
Epoch 00040: val_loss did not improve from 0.96692
100/100 [==============================] - 15s 147ms/step - loss: 0.6936 - acc: 0.7602 - val_loss: 1.1966 - val_acc: 0.6167
Epoch 41/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6995 - acc: 0.7547
Epoch 00041: val_loss did not improve from 0.96692
100/100 [==============================] - 14s 143ms/step - loss: 0.6995 - acc: 0.7545 - val_loss: 1.0735 - val_acc: 0.6419
Epoch 42/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7212 - acc: 0.7483
Epoch 00042: val_loss improved from 0.96692 to 0.87415, saving model to Model.hdf5
100/100 [==============================] - 15s 149ms/step - loss: 0.7203 - acc: 0.7492 - val_loss: 0.8742 - val_acc: 0.7059
Epoch 43/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7134 - acc: 0.7563
Epoch 00043: val_loss did not improve from 0.87415
100/100 [==============================] - 14s 143ms/step - loss: 0.7120 - acc: 0.7566 - val_loss: 0.9345 - val_acc: 0.6807
Epoch 44/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7160 - acc: 0.7508
Epoch 00044: val_loss did not improve from 0.87415
100/100 [==============================] - 14s 144ms/step - loss: 0.7170 - acc: 0.7505 - val_loss: 0.9195 - val_acc: 0.6877
Epoch 45/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7010 - acc: 0.7604
Epoch 00045: val_loss improved from 0.87415 to 0.84720, saving model to Model.hdf5
100/100 [==============================] - 15s 151ms/step - loss: 0.6980 - acc: 0.7616 - val_loss: 0.8472 - val_acc: 0.7140
Epoch 46/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7087 - acc: 0.7546
Epoch 00046: val_loss did not improve from 0.84720
100/100 [==============================] - 14s 144ms/step - loss: 0.7084 - acc: 0.7541 - val_loss: 1.0994 - val_acc: 0.6479
Epoch 47/50
 99/100 [============================>.] - ETA: 0s - loss: 0.7033 - acc: 0.7615
Epoch 00047: val_loss did not improve from 0.84720
100/100 [==============================] - 15s 145ms/step - loss: 0.7024 - acc: 0.7620 - val_loss: 1.3481 - val_acc: 0.5859
Epoch 48/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6383 - acc: 0.7787
Epoch 00048: val_loss did not improve from 0.84720
100/100 [==============================] - 14s 144ms/step - loss: 0.6379 - acc: 0.7783 - val_loss: 0.9031 - val_acc: 0.7072
Epoch 49/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6271 - acc: 0.7828
Epoch 00049: val_loss improved from 0.84720 to 0.83607, saving model to Model.hdf5
100/100 [==============================] - 15s 150ms/step - loss: 0.6262 - acc: 0.7831 - val_loss: 0.8361 - val_acc: 0.7217
Epoch 50/50
 99/100 [============================>.] - ETA: 0s - loss: 0.6353 - acc: 0.7808
Epoch 00050: val_loss did not improve from 0.83607
100/100 [==============================] - 14s 143ms/step - loss: 0.6349 - acc: 0.7809 - val_loss: 0.8494 - val_acc: 0.7103